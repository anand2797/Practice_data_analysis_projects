{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anandtalware/language-detection-practice-8-september-2023?scriptVersionId=143200366\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Language Detection ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-09T12:20:03.255654Z","iopub.execute_input":"2023-09-09T12:20:03.256349Z","iopub.status.idle":"2023-09-09T12:20:04.78989Z","shell.execute_reply.started":"2023-09-09T12:20:03.256311Z","shell.execute_reply":"2023-09-09T12:20:04.788256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# nltk imports","metadata":{}},{"cell_type":"code","source":"import nltk \nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.stem import PorterStemmer\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:04.792681Z","iopub.execute_input":"2023-09-09T12:20:04.793654Z","iopub.status.idle":"2023-09-09T12:20:05.929332Z","shell.execute_reply.started":"2023-09-09T12:20:04.793604Z","shell.execute_reply":"2023-09-09T12:20:05.92787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sklearn imports","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nfrom wordcloud import WordCloud\n\n# Naive Bayes- MultinomialNB\nfrom sklearn.naive_bayes import MultinomialNB","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:05.931034Z","iopub.execute_input":"2023-09-09T12:20:05.931534Z","iopub.status.idle":"2023-09-09T12:20:06.034369Z","shell.execute_reply.started":"2023-09-09T12:20:05.931494Z","shell.execute_reply":"2023-09-09T12:20:06.032951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data fetching in dataframe form","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/language-detection/Language Detection.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.037381Z","iopub.execute_input":"2023-09-09T12:20:06.037811Z","iopub.status.idle":"2023-09-09T12:20:06.154178Z","shell.execute_reply.started":"2023-09-09T12:20:06.037773Z","shell.execute_reply":"2023-09-09T12:20:06.152559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.155773Z","iopub.execute_input":"2023-09-09T12:20:06.15616Z","iopub.status.idle":"2023-09-09T12:20:06.185164Z","shell.execute_reply.started":"2023-09-09T12:20:06.156128Z","shell.execute_reply":"2023-09-09T12:20:06.184065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.186821Z","iopub.execute_input":"2023-09-09T12:20:06.187595Z","iopub.status.idle":"2023-09-09T12:20:06.201837Z","shell.execute_reply.started":"2023-09-09T12:20:06.187554Z","shell.execute_reply":"2023-09-09T12:20:06.200137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before any cleaning in dataset: ')\nprint('Total Records in dataset: ',data.shape[0])\nprint('Total Features in dataset: ', data.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.203502Z","iopub.execute_input":"2023-09-09T12:20:06.203951Z","iopub.status.idle":"2023-09-09T12:20:06.217292Z","shell.execute_reply.started":"2023-09-09T12:20:06.203908Z","shell.execute_reply":"2023-09-09T12:20:06.215786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check missing values in dataset","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.218737Z","iopub.execute_input":"2023-09-09T12:20:06.219796Z","iopub.status.idle":"2023-09-09T12:20:06.25046Z","shell.execute_reply.started":"2023-09-09T12:20:06.219756Z","shell.execute_reply":"2023-09-09T12:20:06.249328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here is not any null value in our dataset.","metadata":{}},{"cell_type":"markdown","source":"# Check Duplicated records in dataset","metadata":{}},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.252507Z","iopub.execute_input":"2023-09-09T12:20:06.253312Z","iopub.status.idle":"2023-09-09T12:20:06.29952Z","shell.execute_reply.started":"2023-09-09T12:20:06.253234Z","shell.execute_reply":"2023-09-09T12:20:06.298369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Here in dataset, we have 66  duplicate records, so we have to drop them.","metadata":{}},{"cell_type":"code","source":"# dropping duplicates\ndata.drop_duplicates(inplace=True)\n\n# check again\ndata.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.304194Z","iopub.execute_input":"2023-09-09T12:20:06.304961Z","iopub.status.idle":"2023-09-09T12:20:06.341148Z","shell.execute_reply.started":"2023-09-09T12:20:06.304917Z","shell.execute_reply":"2023-09-09T12:20:06.339171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normal data information","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.344656Z","iopub.execute_input":"2023-09-09T12:20:06.345102Z","iopub.status.idle":"2023-09-09T12:20:06.373693Z","shell.execute_reply.started":"2023-09-09T12:20:06.345069Z","shell.execute_reply":"2023-09-09T12:20:06.371822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('After any cleaning in dataset: ')\nprint('Total Records in dataset: ',data.shape[0])\nprint('Total Features in dataset: ', data.shape[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.375446Z","iopub.execute_input":"2023-09-09T12:20:06.37624Z","iopub.status.idle":"2023-09-09T12:20:06.384788Z","shell.execute_reply.started":"2023-09-09T12:20:06.376167Z","shell.execute_reply":"2023-09-09T12:20:06.382408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA before preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Value counts of target column","metadata":{}},{"cell_type":"code","source":"data['Language'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.38762Z","iopub.execute_input":"2023-09-09T12:20:06.388365Z","iopub.status.idle":"2023-09-09T12:20:06.411692Z","shell.execute_reply.started":"2023-09-09T12:20:06.388226Z","shell.execute_reply":"2023-09-09T12:20:06.410026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# contplot for Language columns\nsns.countplot(y=data['Language'])\nplt.title('Value Counts for languages')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.414001Z","iopub.execute_input":"2023-09-09T12:20:06.414545Z","iopub.status.idle":"2023-09-09T12:20:06.905112Z","shell.execute_reply.started":"2023-09-09T12:20:06.414499Z","shell.execute_reply":"2023-09-09T12:20:06.903541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# create fuction to preprocess test data\n\nimport string\npunc = string.punctuation\n\n# Define a translation table to remove punctuations\ntranslator = str.maketrans('', '', punc)\n\ndef preprocess_text(text):\n    # convert in lower case\n    lower_text = text.lower()\n    \n    # word tokenization\n    tokens = word_tokenize(text)\n    \n    \n    # remove special charactors and punctuations\n    tokens2 = [token.translate(translator) for token in tokens if token not in punc]\n    \n    # stemming\n    stm = PorterStemmer()\n    stemmed_tokens = [stm.stem(token) for token in tokens2]\n    \n    preprocessed_text = ' '.join(stemmed_tokens)\n    return  preprocessed_text\n\nprint(preprocess_text(data['Text'][1]))","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.906717Z","iopub.execute_input":"2023-09-09T12:20:06.907108Z","iopub.status.idle":"2023-09-09T12:20:06.939372Z","shell.execute_reply.started":"2023-09-09T12:20:06.907074Z","shell.execute_reply":"2023-09-09T12:20:06.937585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creat a new dataset which also has preprocessed text","metadata":{"execution":{"iopub.status.busy":"2023-09-08T12:23:49.188541Z","iopub.execute_input":"2023-09-08T12:23:49.189089Z","iopub.status.idle":"2023-09-08T12:23:49.197245Z","shell.execute_reply.started":"2023-09-08T12:23:49.189047Z","shell.execute_reply":"2023-09-08T12:23:49.195655Z"}}},{"cell_type":"code","source":"data1 = data[['Text', 'Language']]\ndata1['Preprocessed_text'] = data1['Text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:06.940809Z","iopub.execute_input":"2023-09-09T12:20:06.941182Z","iopub.status.idle":"2023-09-09T12:20:17.182938Z","shell.execute_reply.started":"2023-09-09T12:20:06.941148Z","shell.execute_reply":"2023-09-09T12:20:17.181348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:17.184806Z","iopub.execute_input":"2023-09-09T12:20:17.185335Z","iopub.status.idle":"2023-09-09T12:20:17.20022Z","shell.execute_reply.started":"2023-09-09T12:20:17.1853Z","shell.execute_reply":"2023-09-09T12:20:17.19878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check number of unique languages in dataset\ndata1['Language'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:17.202329Z","iopub.execute_input":"2023-09-09T12:20:17.202885Z","iopub.status.idle":"2023-09-09T12:20:17.215367Z","shell.execute_reply.started":"2023-09-09T12:20:17.202833Z","shell.execute_reply":"2023-09-09T12:20:17.213707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud \nwc = WordCloud(width=800, height=500, min_font_size=15, background_color='white')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:17.217468Z","iopub.execute_input":"2023-09-09T12:20:17.217911Z","iopub.status.idle":"2023-09-09T12:20:17.229828Z","shell.execute_reply.started":"2023-09-09T12:20:17.217879Z","shell.execute_reply":"2023-09-09T12:20:17.228343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 1. wordcloud for english language\nenglish_df = data1[data1['Language']=='English']\n\nenglish_words = english_df['Preprocessed_text'].str.cat(sep=' ')\n\nenglish_wc = wc.generate(english_words)\nplt.figure(figsize=(8,8))\nplt.imshow(english_wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:17.232335Z","iopub.execute_input":"2023-09-09T12:20:17.232897Z","iopub.status.idle":"2023-09-09T12:20:18.28711Z","shell.execute_reply.started":"2023-09-09T12:20:17.232854Z","shell.execute_reply":"2023-09-09T12:20:18.285864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1['Language'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:18.288504Z","iopub.execute_input":"2023-09-09T12:20:18.288932Z","iopub.status.idle":"2023-09-09T12:20:18.300071Z","shell.execute_reply.started":"2023-09-09T12:20:18.288888Z","shell.execute_reply":"2023-09-09T12:20:18.298832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"languages = data1['Language'].unique()\nfor lang in languages:\n    print()\n    print('-'*10, lang,'Wordcloud','-'*10)\n    lang_df = data1[data1['Language']==lang]\n\n    lang_words = lang_df['Preprocessed_text'].str.cat(sep=' ')\n\n    lang_wc = wc.generate(lang_words)\n    plt.figure(figsize=(8,8))\n    plt.imshow(lang_wc)\n    plt.axis('off')\n    plt.show()\n    print('=='*30)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:18.302714Z","iopub.execute_input":"2023-09-09T12:20:18.304065Z","iopub.status.idle":"2023-09-09T12:20:37.959836Z","shell.execute_reply.started":"2023-09-09T12:20:18.303999Z","shell.execute_reply":"2023-09-09T12:20:37.958786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1[data1['Language']=='Hindi']","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:37.961491Z","iopub.execute_input":"2023-09-09T12:20:37.963132Z","iopub.status.idle":"2023-09-09T12:20:37.981155Z","shell.execute_reply.started":"2023-09-09T12:20:37.963086Z","shell.execute_reply":"2023-09-09T12:20:37.979965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# checking words counts in each language","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\nlanguages = data1['Language'].unique()\na = 1\nfor lang in languages:\n    print()\n    lang_corpus = []\n    lang_text = data1[data1['Language']==lang]['Preprocessed_text'].tolist()\n    for i in lang_text:\n        for word in i.split():\n            lang_corpus.append(word)\n    print(f\"{a}) Number of words in {lang} : \", len(lang_corpus))\n    print(f'Top 15 words in {lang}:', Counter(lang_corpus).most_common(15))\n    print('='*20)\n    a+=1","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:37.982653Z","iopub.execute_input":"2023-09-09T12:20:37.983158Z","iopub.status.idle":"2023-09-09T12:20:38.164512Z","shell.execute_reply.started":"2023-09-09T12:20:37.983125Z","shell.execute_reply":"2023-09-09T12:20:38.162937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Split data as indepedent and dependent features","metadata":{}},{"cell_type":"code","source":"X = data1['Preprocessed_text']\ny = data1['Language']","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.166085Z","iopub.execute_input":"2023-09-09T12:20:38.166466Z","iopub.status.idle":"2023-09-09T12:20:38.172158Z","shell.execute_reply.started":"2023-09-09T12:20:38.166434Z","shell.execute_reply":"2023-09-09T12:20:38.170871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Train test split","metadata":{}},{"cell_type":"code","source":"X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.174097Z","iopub.execute_input":"2023-09-09T12:20:38.174617Z","iopub.status.idle":"2023-09-09T12:20:38.189979Z","shell.execute_reply.started":"2023-09-09T12:20:38.174569Z","shell.execute_reply":"2023-09-09T12:20:38.188657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('shape of X:', X.shape)\nprint()\nprint('shape of X_train: ',X_train.shape)\nprint('shape of ty_train: ',y_train.shape)\nprint('shape of X_test: ',X_test.shape)\nprint('shape of y_test: ',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.191786Z","iopub.execute_input":"2023-09-09T12:20:38.192248Z","iopub.status.idle":"2023-09-09T12:20:38.204258Z","shell.execute_reply.started":"2023-09-09T12:20:38.192205Z","shell.execute_reply":"2023-09-09T12:20:38.202753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('number of unique langues in y_train: ',y_train.nunique())\nprint('number of unique langues in y_test: ',y_test.nunique())","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.211215Z","iopub.execute_input":"2023-09-09T12:20:38.211651Z","iopub.status.idle":"2023-09-09T12:20:38.220857Z","shell.execute_reply.started":"2023-09-09T12:20:38.211619Z","shell.execute_reply":"2023-09-09T12:20:38.219473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# label encoder for talrget column","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.222805Z","iopub.execute_input":"2023-09-09T12:20:38.223262Z","iopub.status.idle":"2023-09-09T12:20:38.236905Z","shell.execute_reply.started":"2023-09-09T12:20:38.223228Z","shell.execute_reply":"2023-09-09T12:20:38.23558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Vectorization\n## 1. CountVectorization","metadata":{}},{"cell_type":"code","source":"# countvectorizer\ncv = CountVectorizer()\nX_train_cv = cv.fit_transform(X_train).toarray()\nX_test_cv = cv.transform(X_test).toarray()\n\nprint('shape of X:', X.shape)\nprint()\nprint('shape of X_train_cv: ',X_train_cv.shape)\nprint('shape of X_test_cv: ',X_test_cv.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:38.238336Z","iopub.execute_input":"2023-09-09T12:20:38.238902Z","iopub.status.idle":"2023-09-09T12:20:39.119975Z","shell.execute_reply.started":"2023-09-09T12:20:38.238851Z","shell.execute_reply":"2023-09-09T12:20:39.118983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Tf-idf Vectorization","metadata":{}},{"cell_type":"code","source":"# tf-idf vectorizer\ntv = TfidfVectorizer(max_features=2500)\nX_train_tv = tv.fit_transform(X_train).toarray()\nX_test_tv = tv.transform(X_test).toarray()\n\nprint('shape of X:', X.shape)\nprint()\nprint('shape of X_train_tv: ',X_train_tv.shape)\nprint('shape of X_test_tv: ',X_test_tv.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:39.121752Z","iopub.execute_input":"2023-09-09T12:20:39.122605Z","iopub.status.idle":"2023-09-09T12:20:39.866731Z","shell.execute_reply.started":"2023-09-09T12:20:39.122557Z","shell.execute_reply":"2023-09-09T12:20:39.865459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning algorithms","metadata":{}},{"cell_type":"code","source":"# first we check only for Naive Bayes MultinomialNB with countvectorized data\nmnb = MultinomialNB()\nmnb.fit(X_train_cv, y_train_encoded)\ny_pred_mnb_cv = mnb.predict(X_test_cv)\n\n\nprint(\"accuracy score for mnb: \",accuracy_score(y_test_encoded, y_pred_mnb_cv))\nprint()\nprint(\"pricision score for mnb: \",precision_score(y_test_encoded,y_pred_mnb_cv, average='micro'))","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:20:39.868362Z","iopub.execute_input":"2023-09-09T12:20:39.869952Z","iopub.status.idle":"2023-09-09T12:22:09.871446Z","shell.execute_reply.started":"2023-09-09T12:20:39.869905Z","shell.execute_reply":"2023-09-09T12:22:09.866013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# multinomialNB with tfidf\nmnb2 = MultinomialNB()\nmnb2.fit(X_train_tv, y_train_encoded)\ny_pred_mnb_tv = mnb2.predict(X_test_tv)\n\n\nprint(\"accuracy score for mnb: \",accuracy_score(y_test_encoded, y_pred_mnb_tv))\nprint()\nprint(\"pricision score for mnb: \",precision_score(y_test_encoded,y_pred_mnb_tv, average='micro'))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:24:35.339426Z","iopub.execute_input":"2023-09-09T12:24:35.339927Z","iopub.status.idle":"2023-09-09T12:24:35.467778Z","shell.execute_reply.started":"2023-09-09T12:24:35.339889Z","shell.execute_reply":"2023-09-09T12:24:35.46619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we have got better accuracy and precision score with CountVectorized data on Naive Bayes MultinomialNB Machine Learning Model, we store it in .pkl file by using joblib or pickle module for further website or app developement process.","metadata":{}},{"cell_type":"code","source":"import joblib\n\njoblib.dump(mnb, 'multinomialnb.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-09-09T12:25:25.70405Z","iopub.execute_input":"2023-09-09T12:25:25.704582Z","iopub.status.idle":"2023-09-09T12:25:25.729681Z","shell.execute_reply.started":"2023-09-09T12:25:25.704547Z","shell.execute_reply":"2023-09-09T12:25:25.728356Z"},"trusted":true},"execution_count":null,"outputs":[]}]}